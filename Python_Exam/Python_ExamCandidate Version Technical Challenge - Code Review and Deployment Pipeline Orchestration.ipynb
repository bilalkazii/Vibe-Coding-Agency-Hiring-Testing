{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7e0dad4",
   "metadata": {},
   "source": [
    "# Technical Challenge - Code Review and Deployment Pipeline Orchestration\n",
    "\n",
    "**Format:** Structured interview with whiteboarding/documentation  \n",
    "**Assessment Focus:** Problem decomposition, AI prompting strategy, system design\n",
    "\n",
    "**Please Fill in your Responses in the Response markdown boxes**\n",
    "\n",
    "---\n",
    "\n",
    "## Challenge Scenario\n",
    "\n",
    "You are tasked with creating an AI-powered system that can handle the complete lifecycle of code review and deployment pipeline management for a mid-size software company. The system needs to:\n",
    "\n",
    "**Current Pain Points:**\n",
    "- Manual code reviews take 2-3 days per PR\n",
    "- Inconsistent review quality across teams\n",
    "- Deployment failures due to missed edge cases\n",
    "- Security vulnerabilities slip through reviews\n",
    "- No standardized deployment process across projects\n",
    "- Rollback decisions are manual and slow\n",
    "\n",
    "**Business Requirements:**\n",
    "- Reduce review time to <4 hours for standard PRs\n",
    "- Maintain or improve code quality\n",
    "- Catch 90%+ of security vulnerabilities before deployment\n",
    "- Standardize deployment across 50+ microservices\n",
    "- Enable automatic rollback based on metrics\n",
    "- Support multiple environments (dev, staging, prod)\n",
    "- Handle both new features and hotfixes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be761411",
   "metadata": {},
   "source": [
    "## Part A: Problem Decomposition (25 points)\n",
    "\n",
    "**Question 1.1:** Break this challenge down into discrete, manageable steps that could be handled by AI agents or automated systems. Each step should have:\n",
    "- Clear input requirements\n",
    "- Specific output format\n",
    "- Success criteria\n",
    "- Failure handling strategy\n",
    "\n",
    "**Question 1.2:** Which steps can run in parallel? Which are blocking? Where are the critical decision points?\n",
    "\n",
    "**Question 1.3:** Identify the key handoff points between steps. What data/context needs to be passed between each phase?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0a3c10",
   "metadata": {},
   "source": [
    "## Response Part A:\n",
    "\n",
    "AI Code Review System Complete Solution\n",
    "Problem Decomposition\n",
    "1. PR_Analysis_Agent:\n",
    "   - Input: PR metadata, code diff\n",
    "   - Output: Change summary, affected files\n",
    "   - Success: Accurate change identification\n",
    "   - Failure: Fallback to manual review\n",
    "\n",
    "2. Static_Analysis_Agent:\n",
    "   - Input: Code changes  \n",
    "   - Output: Security issues, code smells\n",
    "   - Success: 90% vulnerability detection\n",
    "   - Failure: Flag for human review\n",
    "\n",
    "3. AI_Code_Review_Agent:\n",
    "   - Input: Code + context\n",
    "   - Output: Review comments, suggestions\n",
    "   - Success: <4 hour review time\n",
    "   - Failure: Escalate to senior dev\n",
    "\n",
    "4. Test_Impact_Analysis_Agent:\n",
    "   - Input: Code changes + test suite\n",
    "   - Output: Affected tests, new test needs\n",
    "   - Success: Identify broken tests\n",
    "   - Failure: Run full test suite\n",
    "\n",
    "5. Deployment_Readiness_Agent:\n",
    "   - Input: All previous outputs\n",
    "   - Output: Go/No-go decision\n",
    "   - Success: Correct deployment decision\n",
    "   - Failure: Conservative (No-go)\n",
    "\n",
    "\n",
    "Parallel vs Blocking:\n",
    "Parallel: Static Analysis ↔ Test Impact Analysis\n",
    "Blocking: AI Review (depends on analysis completion)\n",
    "Critical Decision: Deployment Readiness (final gate)\n",
    "\n",
    "Handoff Points:\n",
    "PR Analysis → All agents: Change summary + context\n",
    "Static Analysis → AI Review: Security findings + metrics\n",
    "All agents → Deployment: Consolidated report + confidence scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb38e9fa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fdc377",
   "metadata": {},
   "source": [
    "## Part B: AI Prompting Strategy (30 points)\n",
    "\n",
    "**Question 2.1:** For 2 consecutive major steps you identified, design specific AI prompts that would achieve the desired outcome. Include:\n",
    "- System role/persona definition\n",
    "- Structured input format\n",
    "- Expected output format\n",
    "- Examples of good vs bad responses\n",
    "- Error handling instructions\n",
    "\n",
    "**Question 2.2:** How would you handle the following challenging scenarios with your AI prompts:\n",
    "- **Code that uses obscure libraries or frameworks**\n",
    "- **Security reviews for code**\n",
    "- **Performance analysis of database queries**\n",
    "- **Legacy code modifications**\n",
    "\n",
    "**Question 2.3:** How would you ensure your prompts are working effectively and getting consistent results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd049f5",
   "metadata": {},
   "source": [
    "## Response Part B:\n",
    "\n",
    "Sample Prompts:\n",
    "\n",
    "Prompt 1: Code Review Agent\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a senior software engineer with 10+ years experience.\n",
    "Review this pull request focusing on:\n",
    "\n",
    "CRITICAL AREAS:\n",
    "1. Code quality & best practices\n",
    "2. Potential bugs & edge cases  \n",
    "3. Security vulnerabilities (OWASP Top 10)\n",
    "4. Performance implications\n",
    "5. Maintainability & readability\n",
    "\n",
    "INPUT FORMAT:\n",
    "{\n",
    "  \"code_changes\": [file_diffs],\n",
    "  \"pr_description\": \"string\",\n",
    "  \"repository_context\": \"tech_stack, patterns\",\n",
    "  \"previous_reviews\": [past_comments]\n",
    "}\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "{\n",
    "  \"overall_assessment\": \"APPROVE|REQUEST_CHANGES|COMMENT\",\n",
    "  \"critical_issues\": [\n",
    "    {\n",
    "      \"file\": \"filename\",\n",
    "      \"line\": 123,\n",
    "      \"issue\": \"specific problem\",\n",
    "      \"severity\": \"HIGH|MEDIUM|LOW\", \n",
    "      \"suggestion\": \"concrete fix\"\n",
    "    }\n",
    "  ],\n",
    "  \"suggestions\": [\n",
    "    {\n",
    "      \"file\": \"filename\",\n",
    "      \"line\": 456,\n",
    "      \"suggestion\": \"improvement\",\n",
    "      \"priority\": \"HIGH|MEDIUM|LOW\"\n",
    "    }\n",
    "  ],\n",
    "  \"questions\": [\"clarification questions for author\"],\n",
    "  \"confidence_score\": 0.95\n",
    "}\n",
    "\n",
    "EXAMPLES:\n",
    "GOOD: \"Found SQL injection vulnerability in user_id parameter - use parameterized queries\"\n",
    "BAD: \"Looks good to me\" (too vague)\n",
    "\"\"\"\n",
    "\n",
    "Prompt 2: Security Review Agent\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a security specialist focusing on application security.\n",
    "Identify security vulnerabilities using OWASP Top 10 framework.\n",
    "\n",
    "SPECIFIC CHECKS:\n",
    "- Injection vulnerabilities (SQL, NoSQL, Command)\n",
    "- Broken authentication & session management\n",
    "- Sensitive data exposure\n",
    "- XML external entities (XXE)\n",
    "- Broken access control\n",
    "- Security misconfigurations\n",
    "- Cross-site scripting (XSS)\n",
    "- Insecure deserialization\n",
    "- Using components with known vulnerabilities\n",
    "- Insufficient logging & monitoring\n",
    "\n",
    "ERROR HANDLING:\n",
    "- If unfamiliar with library/framework, flag for expert review\n",
    "- When uncertain, prioritize security (conservative approach)\n",
    "- Provide specific remediation steps for each finding\n",
    "\"\"\"\n",
    "Challenging Scenarios Handling:\n",
    "\n",
    "# Obscure Libraries:\n",
    "\"Focus on general security patterns. If library is unfamiliar, check for: \n",
    "- Input validation boundaries\n",
    "- Output encoding requirements\n",
    "- Authentication/authorization flows\n",
    "- Data serialization/deserialization\"\n",
    "\n",
    "# Security Reviews:\n",
    "\"Apply defense-in-depth principles:\n",
    "1. Input validation at boundaries\n",
    "2. Output encoding for context\n",
    "3. Principle of least privilege\n",
    "4. Secure default configurations\"\n",
    "\n",
    "# Performance Analysis:\n",
    "\"Analyze for:\n",
    "- N+1 query patterns\n",
    "- Missing database indexes\n",
    "- Inefficient algorithms (O(n^2) vs O(n log n))\n",
    "- Memory leaks & resource management\"\n",
    "\n",
    "# Legacy Code:\n",
    "\"Risk-based approach:\n",
    "- Identify critical security fixes\n",
    "- Suggest incremental improvements\n",
    "- Focus on attack surface reduction\n",
    "- Document technical debt\"\n",
    "\n",
    "\n",
    "Ensuring Prompt Effectiveness:\n",
    "validation_strategy = {\n",
    "    \"golden_dataset\": \"Test prompts against known good/bad code samples\",\n",
    "    \"multi_llm_consensus\": \"Use 2-3 different LLMs and compare results\",\n",
    "    \"false_positive_tracking\": \"Monitor and tune based on FP/FN rates\",\n",
    "    \"developer_feedback\": \"Incorporate real developer feedback into prompt tuning\",\n",
    "    \"regular_evaluation\": \"Monthly review of prompt effectiveness metrics\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476e98d3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d353d",
   "metadata": {},
   "source": [
    "## Part C: System Architecture & Reusability (25 points)\n",
    "\n",
    "**Question 3.1:** How would you make this system reusable across different projects/teams? Consider:\n",
    "- Configuration management\n",
    "- Language/framework variations\n",
    "- Different deployment targets (cloud providers, on-prem)\n",
    "- Team-specific coding standards\n",
    "- Industry-specific compliance requirements\n",
    "\n",
    "**Question 3.2:** How would the system get better over time based on:\n",
    "- False positive/negative rates in reviews\n",
    "- Deployment success/failure patterns\n",
    "- Developer feedback\n",
    "- Production incident correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0052f045",
   "metadata": {},
   "source": [
    "## Response Part C:\n",
    "\n",
    "& Reusability--------------------\n",
    "\n",
    "Making System Reusable:\n",
    "configuration_template = {\n",
    "    \"team_specific_rules\": {\n",
    "        \"backend_team\": {\"focus_areas\": [\"api_security\", \"database_performance\"]},\n",
    "        \"frontend_team\": {\"focus_areas\": [\"xss_prevention\", \"ui_performance\"]},\n",
    "        \"mobile_team\": {\"focus_areas\": [\"data_storage\", \"network_security\"]}\n",
    "    },\n",
    "    \"language_support\": {\n",
    "        \"python\": {\"tools\": [\"pylint\", \"bandit\", \"safety\"]},\n",
    "        \"javascript\": {\"tools\": [\"eslint\", \"npm_audit\"]},\n",
    "        \"java\": {\"tools\": [\"spotbugs\", \"dependency_check\"]}\n",
    "    },\n",
    "    \"deployment_targets\": {\n",
    "        \"aws\": {\"services\": [\"CodeDeploy\", \"ECS\", \"Lambda\"]},\n",
    "        \"azure\": {\"services\": [\"Azure DevOps\", \"AKS\"]},\n",
    "        \"on_prem\": {\"services\": [\"Jenkins\", \"Kubernetes\"]}\n",
    "    }\n",
    "}\n",
    "\n",
    "Continuous Improvement:\n",
    "learning_framework = {\n",
    "    \"false_positive_analysis\": {\n",
    "        \"track_patterns\": \"Common FP patterns across teams\",\n",
    "        \"adjust_thresholds\": \"Tune sensitivity based on FP rates\",\n",
    "        \"update_prompts\": \"Refine AI prompts based on FP analysis\"\n",
    "    },\n",
    "    \"deployment_correlation\": {\n",
    "        \"success_patterns\": \"What review comments correlate with successful deployments?\",\n",
    "        \"failure_patterns\": \"What missed issues cause production incidents?\",\n",
    "        \"feedback_loop\": \"Use incident data to improve review criteria\"\n",
    "    },\n",
    "    \"developer_feedback_incorporation\": {\n",
    "        \"rating_system\": \"Developers rate review quality\",\n",
    "        \"comment_effectiveness\": \"Which suggestions are actually implemented?\",\n",
    "        \"preference_learning\": \"Learn team-specific review preferences\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6029f169",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d096eb",
   "metadata": {},
   "source": [
    "## Part D: Implementation Strategy (20 points)\n",
    "\n",
    "**Question 4.1:** Prioritize your implementation. What would you build first? Create a 6-month roadmap with:\n",
    "- MVP definition (what's the minimum viable system?)\n",
    "- Pilot program strategy\n",
    "- Rollout phases\n",
    "- Success metrics for each phase\n",
    "\n",
    "**Question 4.2:** Risk mitigation. What could go wrong and how would you handle:\n",
    "- AI making incorrect review decisions\n",
    "- System downtime during critical deployments\n",
    "- Integration failures with existing tools\n",
    "- Resistance from development teams\n",
    "- Compliance/audit requirements\n",
    "\n",
    "**Question 4.3:** Tool selection. What existing tools/platforms would you integrate with or build upon:\n",
    "- Code review platforms (GitHub, GitLab, Bitbucket)\n",
    "- CI/CD systems (Jenkins, GitHub Actions, GitLab CI)\n",
    "- Monitoring tools (Datadog, New Relic, Prometheus)\n",
    "- Security scanning tools (SonarQube, Snyk, Veracode)\n",
    "- Communication tools (Slack, Teams, Jira)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa9820",
   "metadata": {},
   "source": [
    "## Response Part D:\n",
    "\n",
    "Month Roadmap:\n",
    "roadmap = {\n",
    "    \"Month 1-2: MVP\": [\n",
    "        \"Basic PR analysis integration\",\n",
    "        \"Simple static analysis (existing tools)\",\n",
    "        \"GitHub/GitLab webhook setup\",\n",
    "        \"Basic reporting dashboard\"\n",
    "    ],\n",
    "    \"Month 3-4: Enhanced Features\": [\n",
    "        \"AI code review integration\",\n",
    "        \"Test impact analysis\",\n",
    "        \"Basic deployment gates\",\n",
    "        \"Team-specific configurations\"\n",
    "    ],\n",
    "    \"Month 5-6: Advanced Capabilities\": [\n",
    "        \"Automated rollback triggers\",\n",
    "        \"Multi-environment support\",\n",
    "        \"Advanced analytics & reporting\",\n",
    "        \"Self-learning improvements\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "Risk Mitigation:\n",
    "\n",
    "risk_plan = {\n",
    "    \"ai_incorrect_decisions\": {\n",
    "        \"human_fallback\": \"Critical changes always require human review\",\n",
    "        \"confidence_thresholds\": \"Only auto-approve high-confidence reviews\",\n",
    "        \"gradual_rollout\": \"Start with non-critical repositories\"\n",
    "    },\n",
    "    \"system_downtime\": {\n",
    "        \"fallback_mode\": \"Revert to manual process during outages\",\n",
    "        \"circuit_breakers\": \"Fail open for critical deployments\",\n",
    "        \"monitoring\": \"Real-time alerting for system health\"\n",
    "    },\n",
    "    \"team_resistance\": {\n",
    "        \"opt_in_phases\": \"Teams can choose when to adopt\",\n",
    "        \"training_program\": \"Comprehensive onboarding\",\n",
    "        \"success_metrics\": \"Show tangible benefits (time saved, quality improved)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "Tool Integration:\n",
    "tool_ecosystem = {\n",
    "    \"code_review_platforms\": [\"GitHub\", \"GitLab\", \"Bitbucket\"],\n",
    "    \"ci_cd_systems\": [\"Jenkins\", \"GitHub Actions\", \"GitLab CI\", \"CircleCI\"],\n",
    "    \"monitoring_tools\": [\"Datadog\", \"New Relic\", \"Prometheus\", \"Grafana\"],\n",
    "    \"security_scanners\": [\"SonarQube\", \"Snyk\", \"Veracode\", \"Checkmarx\"],\n",
    "    \"communication_tools\": [\"Slack\", \"Microsoft Teams\", \"Jira\", \"Confluence\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584added",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
